{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d54467e-511f-4bc1-a8d7-57642c345c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import plotly.express as px\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, ConfusionMatrixDisplay, silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94655c9d-0bdf-4933-b219-fab8425b797b",
   "metadata": {},
   "source": [
    "# Part 1: Forest Cover Type\n",
    "## Section A:Data Exploration & Visualization\n",
    "### Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5e116f-e272-4089-bcc3-a8d73342acf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df0 = pd.read_csv(\"treetypes.csv\", index_col=0)\n",
    "df = df0.reset_index()\n",
    "# Display the first few rows of the dataset\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd09758-d03b-4154-b4cb-e0f53d9f2032",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bace58d-620a-488c-8bfc-747225dabc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate descriptive statistics\n",
    "print(\"Descriptive Statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79929e8d-3b2e-4ebe-b2e1-68d1bba2e57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values Count:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04367bf4-ac04-4938-a7ad-2e3b08b9f17e",
   "metadata": {},
   "source": [
    "This dataset contains 45,000 entries and 54 columns, with features like Aspect, Slope, Hillshade at different times of day, and distances to hydrology, roadways, and fire points. It also includes many one-hot encoded soil and wilderness types. Most features are numeric, while categorical features are represented as binary columns. Elevation was originally used as the index, but we modified the dataset to treat it as a feature, resetting the index to default (0, 1, 2, ...). The dataset appears clean and ready for modeling. We will proceed with any required preprocessing in section B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11636e9-601a-4bbf-bc87-4b5f1fee785c",
   "metadata": {},
   "source": [
    "### Understanding the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51470e1d-e0a1-449a-b1b2-2a7b9352b555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total counts of each Wilderness_Area (1–4) per tree type\n",
    "wilderness_cols = [col for col in df.columns if col.startswith(\"Wilderness_Area\")]\n",
    "wilderness_counts = df.groupby(\"label\")[wilderness_cols].sum()\n",
    "\n",
    "# Rename columns for clearer labels\n",
    "wilderness_counts.columns = [col.replace(\"Wilderness_Area\", \"Area \") for col in wilderness_counts.columns]\n",
    "\n",
    "# Plot: stacked bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "wilderness_counts.plot(kind=\"bar\", stacked=True, colormap=\"Set2\", figsize=(10, 6))\n",
    "plt.title(\"Distribution of Wilderness Areas per Tree Type\")\n",
    "plt.xlabel(\"Tree Type (Label)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title=\"Wilderness Area\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e910fecc-c677-4b01-9598-17e309de07de",
   "metadata": {},
   "source": [
    "##### Observation:\n",
    "This stacked bar plot shows the distribution of wilderness areas across tree types. Label 3 is heavily concentrated in Wilderness Area 4, making this feature a strong predictor for identifying Label 3. In contrast, Labels 1 and 2 appear in similar proportions across Areas 1–3, offering little discriminative value. This confirms that Wilderness Area 4 should be treated as a signal feature, while the others may be less useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508e9170-92d0-4817-853f-0fd8a2168840",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=df, x=\"Slope\", y=\"Elevation\", hue=\"label\", palette=\"tab10\", alpha=0.5)\n",
    "plt.title(\"Elevation vs. Slope by Tree Type\")\n",
    "plt.xlabel(\"Slope\")\n",
    "plt.ylabel(\"Elevation\")\n",
    "plt.legend(title=\"Tree Type\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4512047-085b-48f0-a0b7-a0df0935f7f9",
   "metadata": {},
   "source": [
    "##### Observation:\n",
    "This scatter plot visualizes the relationship between elevation and slope across tree types. Label 3 stands out clearly in the low-elevation, low-slope region, while Labels 1 and 2 overlap heavily. This confirms elevation’s strength as a predictive feature and suggests that slope alone is not very informative — most of the observed separation is driven by elevation. Therefore, while slope may contribute minor contextual value in multivariate models, it is not a strong feature by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98bd684-84d3-4401-bb5e-54221afa638d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the soil usage matrix\n",
    "soil_cols = [col for col in df.columns if col.startswith(\"Soil_Type\")]\n",
    "soil_usage = df.groupby(\"label\")[soil_cols].sum()\n",
    "\n",
    "# Melt the dataframe to long format\n",
    "soil_usage_long = soil_usage.reset_index().melt(id_vars='label', var_name='Soil_Type', value_name='Count')\n",
    "\n",
    "# Get top 5 soil types per tree type — updated to avoid the warning\n",
    "top5_soils_per_label = (\n",
    "    soil_usage_long\n",
    "    .sort_values([\"label\", \"Count\"], ascending=[True, False])\n",
    "    .groupby(\"label\", group_keys=False)\n",
    "    .head(5)\n",
    ")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=top5_soils_per_label, x=\"label\", y=\"Count\", hue=\"Soil_Type\", palette=\"tab20\")\n",
    "plt.title(\"Top 5 Soil Types per Tree Type\")\n",
    "plt.xlabel(\"Tree Type (Label)\")\n",
    "plt.ylabel(\"Occurrences\")\n",
    "plt.legend(title=\"Soil Type\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6ec8ad-acf6-42a7-a119-fddcb55e9c8c",
   "metadata": {},
   "source": [
    "##### Observation:\n",
    "This plot shows the top 5 most common soil types per tree label. It reveals that Label 3 strongly favors certain soil types that are rare in other labels, making soil type a highly predictive feature for separating Label 3. Labels 1 and 2 share more overlap in soil usage but still show minor differences (e.g., Soil_Type22 for Label 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b587df16-72e3-420b-a841-0f17b03dfc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Elevation\"] = pd.to_numeric(df[\"Elevation\"], errors=\"coerce\")\n",
    "df_1 = df[df[\"label\"].isin([1, 2, 3])]  # Filter only labels 1, 2, 3\n",
    "df_1 = df_1.dropna(subset=[\"Elevation\"])  # Remove any null elevation\n",
    "\n",
    "# Map labels to colors\n",
    "label_color_map = {1: \"blue\", 2: \"green\", 3: \"red\"}\n",
    "label_name_map = {1: \"Label 1\", 2: \"Label 2\", 3: \"Label 3\"}\n",
    "\n",
    "# Plot KDEs manually by label\n",
    "plt.figure(figsize=(8, 6))\n",
    "for label in [1, 2, 3]:\n",
    "    subset = df_1[df_1[\"label\"] == label]\n",
    "    sns.kdeplot(\n",
    "        data=subset,\n",
    "        x=\"Elevation\",\n",
    "        fill=True,\n",
    "        alpha=0.4,\n",
    "        linewidth=1.5,\n",
    "        color=label_color_map[label],\n",
    "        label=label_name_map[label]\n",
    "    )\n",
    "\n",
    "# Final plot settings\n",
    "plt.title(\"Elevation Distribution by Tree Type (Labels 1, 2, 3)\")\n",
    "plt.xlabel(\"Elevation\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend(title=\"Tree Type\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a4bb8c-f8c9-4e39-81ac-22255e408909",
   "metadata": {},
   "source": [
    "##### Observation:\n",
    "This KDE plot shows the elevation distributions for Labels 1, 2, and 3. Label 3 stands out with a clearly lower elevation range, making Elevation an excellent feature for isolating it. While Labels 1 and 2 overlap more heavily, Label 2 tends to appear at slightly higher elevations. This makes Elevation a strong but imperfect predictor across all labels, particularly useful for distinguishing Label 3. This insight supports using Elevation prominently in modeling and feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115f1de1-85f8-4ae9-906b-3a31c303af07",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['Horizontal_Distance_To_Hydrology', 'Horizontal_Distance_To_Fire_Points','Hillshade_Noon', 'Hillshade_9am', 'Hillshade_3pm', 'label']\n",
    "df_subset = df[selected_features].copy()\n",
    "\n",
    "# Filter only labels 1 and 2\n",
    "df_subset = df_subset[df_subset[\"label\"].isin([1, 2])]\n",
    "df_subset[\"label\"] = df_subset[\"label\"].astype(str)  # ensure string for coloring\n",
    "\n",
    "# Plot\n",
    "sns.pairplot(df_subset, hue='label',\n",
    "             palette={'1': 'lightgreen', '2': 'salmon'},\n",
    "             plot_kws={'alpha': 1, 's': 20})\n",
    "\n",
    "plt.suptitle('Pairplot of Selected Features by Tree Type (Label 1 vs 2)', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144fb879-1018-4d37-bea1-a78844bb8bea",
   "metadata": {},
   "source": [
    "##### Observation:\n",
    "This pairplot explores terrain and light-related features for Label 1 vs 2. All four features show substantial overlap between the labels, both individually and in combination. While this plot does not reveal strong separation, it’s important as it confirms that these features alone are not sufficient for distinguishing the two labels. This insight will guide our model design to rely on multi-feature combinations rather than isolated features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58888316-4420-4a78-b3fa-9b079ff7b8ee",
   "metadata": {},
   "source": [
    "## Section B - Data Pre-processing\n",
    "p.s we do not need to clean the dataset before feature engineering since we have no null values and all data have the correct type\n",
    "### feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00971a0c-4f30-41f4-b0a7-a04553092493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the dataset\n",
    "df0 = pd.read_csv(\"treetypes.csv\", index_col=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11ded84-f889-4aae-9f71-4909e2784ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Hydrology Vertical/Horizontal Ratio\n",
    "df0[\"Hydrology_VH_Ratio\"] = df0[\"Vertical_Distance_To_Hydrology\"] / (df0[\"Horizontal_Distance_To_Hydrology\"] + 1)\n",
    "\n",
    "# 2. Total Horizontal Distance (Fire + Road + Water)\n",
    "df0[\"Total_Horiz_Distance\"] = (\n",
    "    df0[\"Horizontal_Distance_To_Hydrology\"] +\n",
    "    df0[\"Horizontal_Distance_To_Fire_Points\"] +\n",
    "    df0[\"Horizontal_Distance_To_Roadways\"]\n",
    ")\n",
    "\n",
    "# 3. Hillshade Range (max - min of 3 times)\n",
    "hillshade_cols = [\"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\"]\n",
    "df0[\"Hillshade_Range\"] = df0[hillshade_cols].max(axis=1) - df0[hillshade_cols].min(axis=1)\n",
    "\n",
    "# 4. Downhill to Water (binary: 1 if slope down to hydrology)\n",
    "df0[\"Downhill_To_Water\"] = (df0[\"Vertical_Distance_To_Hydrology\"] < 0).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffceba3-e37c-4585-8eab-2812b63214e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return updated dataframe shape and columns added\n",
    "df0.shape, df0.columns[0:].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5e4f7e-a63e-487d-bee5-1f93bad1899a",
   "metadata": {},
   "source": [
    "| Feature Name                  | Formula / Description                                                                 | Reason to Add                                                                 |\n",
    "|------------------------------|----------------------------------------------------------------------------------------|--------------------------------------------------------------------------------|\n",
    "| `Total_Horiz_Distance`       | Sum of horizontal distances to Hydrology, Fire Points, and Roadways                   | Captures total remoteness from infrastructure — affects environment and tree growth |\n",
    "| `Hydrology_VH_Ratio`         | Vertical ÷ (Horizontal + 1) distance to hydrology                                     | Approximates terrain slope toward water — steeper slopes may affect soil or runoff  |\n",
    "| `Downhill_To_Water`          | Boolean: 1 if Vertical Distance to Hydrology < 0                                      | Indicates whether terrain descends toward water — may influence moisture or erosion |\n",
    "| `Hillshade_Range`            | Max - Min of Hillshade at 9am, Noon, 3pm                                              | Captures variation in sunlight exposure across the day — relevant to shade tolerance |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883437e1-86b2-48cd-b05c-457818448dc9",
   "metadata": {},
   "source": [
    "### Data Cleaning after geature engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e0c2bb-c0ee-4858-9755-7b7b2036ebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0225f183-d5f7-4293-b91b-47b39a9463c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the relevant features to scale\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df0[[\"Total_Horiz_Distance\", \"Hydrology_VH_Ratio\"]])\n",
    "scaled_df = pd.DataFrame(scaled_features, columns=[\"Total_Horiz_Distance_Scaled\", \"Hydrology_VH_Ratio_Scaled\"])\n",
    "\n",
    "# Merge the scaled features into the original DataFrame\n",
    "df0 = pd.concat([df0, scaled_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d52f8a-22ff-40c7-bcb9-bf28f8a02fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any columns that have only a single unique value\n",
    "useless_cols = [col for col in df0.columns if df0[col].nunique() <= 1]\n",
    "print(useless_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fd14a8-00e3-4b40-94de-e854bb534aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.drop(columns=[\"Soil_Type15\", \"Soil_Type37\"], inplace=True)\n",
    "df0.drop(columns=[\"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\"], inplace=True)\n",
    "df0.drop(columns=[\"Horizontal_Distance_To_Roadways\",\"Horizontal_Distance_To_Fire_Points\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb77a020-8d7f-4865-9c3d-7ffa7505f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data Cleaning Completed\\n')\n",
    "df0.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a324801-fb7e-4daf-b346-f0263abb50d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.describe().T.sort_values('std', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe33d7c4-3b16-4948-a66c-06cb3c64913f",
   "metadata": {},
   "source": [
    "### Full Data Cleaning and Preprocessing Summary\n",
    "\n",
    "This section outlines the complete data preparation process used to convert the raw `treetypes.csv` dataset into a model-ready format for tree classification. All decisions were made to ensure compatibility with models such as KNN, Random Forest, Gradient Boosting, and PCA, while preserving informative environmental and terrain features.\n",
    "\n",
    "#### 1. Feature Engineering\n",
    "\n",
    "We constructed several informative features based on domain intuition and terrain analysis:\n",
    "\n",
    "- `Total_Horiz_Distance`: Sum of horizontal distances to hydrology, fire points, and roadways. This measures a tree's overall remoteness from manmade and natural infrastructure.\n",
    "- `Hydrology_VH_Ratio`: Vertical ÷ (Horizontal + 1) distance to hydrology. This ratio approximates the steepness of terrain sloping into water — important for soil runoff and water exposure.\n",
    "- `Downhill_To_Water`: Boolean flag equal to 1 if a tree is located downhill from hydrology (i.e., `Vertical_Distance_To_Hydrology` < 0). This may affect water saturation and erosion.\n",
    "- `Hillshade_Range`: The difference between the maximum and minimum hillshade across 9am, Noon, and 3pm. Captures terrain-related variation in sunlight exposure.\n",
    "\n",
    "All engineered features are numeric and additive — enhancing model input while preserving interpretability.\n",
    "\n",
    "#### 2. Scaling for PCA and KNN\n",
    "\n",
    "Two continuous features were scaled using `StandardScaler` to ensure compatibility with distance-based models:\n",
    "\n",
    "- `Total_Horiz_Distance_Scaled`: Standardized version of total horizontal distance.\n",
    "- `Hydrology_VH_Ratio_Scaled`: Standardized version of the hydrology slope ratio.\n",
    "\n",
    "The original versions were retained for tree-based models which do not require scaling.\n",
    "\n",
    "#### 3. Redundant Feature Removal\n",
    "\n",
    "Two soil type features were found to be entirely unused in the dataset (i.e., all values were zero):\n",
    "\n",
    "- `Soil_Type15`\n",
    "- `Soil_Type37`\n",
    "\n",
    "Features that were non-informative, textual, or already incorporated through feature engineering:\n",
    "\n",
    "- `Hillshade_9am`\n",
    "- `Hillshade_Noon`\n",
    "- `Hillshade_3pm`\n",
    "- `Horizontal_Distance_To_Roadways`\n",
    "- `Horizontal_Distance_To_Fire_Points`\n",
    "\n",
    "These were dropped to reduce feature noise and improve efficiency.\n",
    "\n",
    "#### 4. Final Dataset Verification\n",
    "\n",
    "- All features are numeric (`float64` or `int64`)\n",
    "- No missing values, infinite values, or constant columns remain\n",
    "- Dataset retains full structure and balance: ~45,000 samples × 50+ informative features\n",
    "- All engineered and scaled features are now available for modeling in Sections C and D\n",
    "\n",
    "The resulting dataset is now fully cleaned, transformed, and ready for model training, PCA, and classification evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3142a35-c181-446d-861e-7204dc644727",
   "metadata": {},
   "source": [
    "## Section C - Classification and Clustering\n",
    "\n",
    "for classification We have chosen these three models:\n",
    "- random forest\n",
    "- GBoost with Tree\n",
    "- Neural Networks \n",
    "\n",
    "for clustering we have chosen these two models:\n",
    "- K-Means\n",
    "- Agglomerative Clustering\n",
    "\n",
    "## Section C.1 - Classification\n",
    "\n",
    "### Section C.1.1 - Setup and Data Preparation\n",
    "\n",
    "In this section, we prepare the dataset for modeling. We define the features (X) and target (y),\n",
    "split the data into train, validation, and test sets using an 80/10/10 split, as required by the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b2c918-e263-49b9-b930-83d478412c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target\n",
    "X = df0.drop(columns=['label'])\n",
    "y = df0['label']\n",
    "\n",
    "# Split: 80/10/10\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e80220-c3a5-4937-946d-e6557576b4f1",
   "metadata": {},
   "source": [
    "### Section C.1.2 - Model: Random Forest\n",
    "\n",
    "We train a Random Forest classifier using GridSearchCV to tune `n_estimators`, `max_depth`, and apply `class_weight='balanced'`\n",
    "for handling class imbalance. Evaluation is based on Macro F1 to ensure fairness to both classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454ba1c9-12d6-4732-8da3-48f29130885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'class_weight': ['balanced']}\n",
    "\n",
    "rf_gs = GridSearchCV(RandomForestClassifier(random_state=42),rf_params,scoring='f1_macro', cv=3,n_jobs=-1)\n",
    "rf_gs.fit(X_train, y_train)\n",
    "print(\"Best RF Params:\", rf_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f628da2f-68a2-42d6-88cb-788ebbdd6786",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = rf_gs.best_estimator_\n",
    "y_val_pred_rf = rf_best.predict(X_val)\n",
    "y_test_pred_rf = rf_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23578b59-becf-4048-bc2b-52bddbbe9ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(rf_best, X_val, y_val, cmap='Blues')\n",
    "plt.title(\"Random Forest - Validation Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3da3360-bc02-4792-8a1b-20464f6596c9",
   "metadata": {},
   "source": [
    "Random Forest Summary:\n",
    "- Tuned using GridSearchCV with 3-fold CV.\n",
    "- Best parameters were `class_weight='balanced'`, `max_depth=None`, and `n_estimators=200`.\n",
    "- Performed strongly overall, with very high accuracy across all three classes.\n",
    "- Class 3 had nearly perfect classification (1,495 correct predictions, only 5 misclassified as class 2).\n",
    "- Most errors occurred between classes 1 and 2 (182 class 1 instances predicted as class 2, and 186 class 2 instances predicted as class 1), which is what was predicted since we've seen in section A how much they overlap.\n",
    "- No confusion was observed between classes 1 and 3, indicating they are well-separated in feature space.\n",
    "\n",
    "### Section C.1.3 - Model: Gradient Boosting\n",
    "\n",
    "Next, we train a Gradient Boosting classifier, tuning tree depth, learning rate, and number of trees.\n",
    "This model handles tends to perform well when tuned properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af354c32-c2a1-46f1-8d95-a605ceb8d5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define parameter grid\n",
    "gboost_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "# Step 2: GridSearchCV using macro F1 \n",
    "gboost_gs = GridSearchCV(\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    gboost_params,\n",
    "    scoring='f1_macro',\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "gboost_gs.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Get best hyperparameters from grid search\n",
    "gboost_best = gboost_gs.best_estimator_\n",
    "\n",
    "# Step 4: Make predictions\n",
    "y_val_pred_gb = gboost_best.predict(X_val)\n",
    "y_test_pred_gb = gboost_best.predict(X_test)\n",
    "\n",
    "# Step 5: (Optional) Evaluate F1 scores\n",
    "val_f1_gb = f1_score(y_val, y_val_pred_gb, average='macro')\n",
    "test_f1_gb = f1_score(y_test, y_test_pred_gb, average='macro')\n",
    "\n",
    "print(\"Validation Macro F1 Score:\", val_f1_gb)\n",
    "print(\"Test Macro F1 Score:\", test_f1_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592d1361-adf3-4dc2-8b06-ecbbe50bf127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix - Gradient Boosting\n",
    "ConfusionMatrixDisplay.from_estimator(gboost_best, X_val, y_val, cmap='Purples')\n",
    "plt.title(\"GBoost - Validation Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06f4439-07bf-4967-867b-9fedb54029bc",
   "metadata": {},
   "source": [
    "Gradient Boosting Summary:\n",
    "- Tuned tree depth, number of trees, and learning rate.\n",
    "- ....\n",
    "### Section C.1.4 - Model: Neural Networks\n",
    "\n",
    "Neural Network rquire...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83ab5ab-4555-457f-8ec7-0c5fc3a9ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622cf11d-1933-45ff-93ec-ef1ba5375fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_params = { 'hidden_layer_sizes': [(50,), (100,), (100, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['constant', 'adaptive']}\n",
    "\n",
    "# Step 2: GridSearchCV using macro F1 to tune \n",
    "mlp_gs = GridSearchCV(MLPClassifier(max_iter=500, early_stopping=True, random_state=42) ,mlp_params,scoring='f1_macro', cv=3,n_jobs=-1)\n",
    "mlp_gs.fit(X_train_scaled, y_train)\n",
    "print(\"Best MLP Params:\", mlp_gs.best_params_)\n",
    "\n",
    "# Step 3: Get best hyperparameters from grid search\n",
    "mlp_best = mlp_gs.best_estimator_\n",
    "\n",
    "# Step 4: Make predictions\n",
    "y_val_pred_mlp = mlp_best.predict(X_val_scaled)\n",
    "y_test_pred_mlp = mlp_best.predict(X_test_scaled)\n",
    "\n",
    "# Step 5: (Optional) Evaluate F1 scores\n",
    "val_f1_mpl = f1_score(y_val, y_val_pred_mlp, average='macro')\n",
    "test_f1_mpl = f1_score(y_test, y_test_pred_mlp, average='macro')\n",
    "\n",
    "print(\"Validation Macro F1 Score:\", val_f1_mpl)\n",
    "print(\"Test Macro F1 Score:\", test_f1_mpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84854871-324a-4468-b442-10ad719f986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(mlp_best, X_val, y_val, cmap='Blues')\n",
    "plt.title(\"Neural Networks (Multi Layer Perception Classifier) - Validation Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab666ec-19b5-476f-a2d8-7c0f4b323002",
   "metadata": {},
   "source": [
    "Neural Networks summary:\n",
    "- .....\n",
    "- .....\n",
    "\n",
    "### Section C.1.5 - VotingClassifier Ensemble \n",
    "\n",
    "We ensemble the three models using a VotingClassifier.\n",
    "We refit the SVM using `probability=True`, which is required for soft voting.\n",
    "Although we use hard voting here, this configuration gives us flexibility to easily switch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e6ca91-0574-4d3f-9139-c85e673eccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting = VotingClassifier(estimators=[('rf', rf_best), ('gb', gboost_best), ('mlp', mlp_best)], voting='soft')\n",
    "\n",
    "voting.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_val_pred_vote = voting.predict(X_val_scaled)\n",
    "print(\"VotingClassifier - Validation F1:\", f1_score(y_val, y_val_pred_vote, average='macro'), \"\\n\")\n",
    "print(classification_report(y_val, y_val_pred_vote))\n",
    "\n",
    "# Test predictions\n",
    "y_test_pred_vote = voting.predict(X_test_scaled)\n",
    "print(\"VotingClassifier - Test F1:\", f1_score(y_test, y_test_pred_vote, average='macro'), \"\\n\")\n",
    "print(classification_report(y_test, y_test_pred_vote))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f71ef9-7020-4596-8e65-aff0352886b3",
   "metadata": {},
   "source": [
    "Voting ensemble summary:\n",
    "\n",
    "- ...\n",
    "- ...\n",
    "- ...\n",
    "\n",
    "### Section C.1.6 - Model Comparison and Evaluation\n",
    "\n",
    "We compare all three models (RF, GBoost, Nueral Networks (MLP)) using both accuracy and macro F1.\n",
    "A bar chart is used to visualize model performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dd15a5-e463-4933-b5ca-c788a30670cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate macro F1\n",
    "metrics_summary = {\n",
    "    'Model': ['Random Forest', 'GBoost', 'Neural Networks'],\n",
    "    'Val Accuracy': [\n",
    "        accuracy_score(y_val, y_val_pred_rf),\n",
    "        accuracy_score(y_val, y_val_pred_gb),\n",
    "        accuracy_score(y_val, y_val_pred_mlp)\n",
    "    ],\n",
    "    'Val Macro F1': [\n",
    "        f1_score(y_val, y_val_pred_rf, average='macro'),\n",
    "        f1_score(y_val, y_val_pred_gb, average='macro'),\n",
    "        f1_score(y_val, y_val_pred_mlp, average='macro')\n",
    "    ],\n",
    "    'Test Accuracy': [\n",
    "        accuracy_score(y_test, y_test_pred_rf),\n",
    "        accuracy_score(y_test, y_test_pred_gb),\n",
    "        accuracy_score(y_test, y_test_pred_mlp)\n",
    "    ],\n",
    "    'Test Macro F1': [\n",
    "        f1_score(y_test, y_test_pred_rf, average='macro'),\n",
    "        f1_score(y_test, y_test_pred_gb, average='macro'),\n",
    "        f1_score(y_test, y_test_pred_mlp, average='macro')\n",
    "    ]\n",
    "}\n",
    "# Add VotingClassifier to the summary\n",
    "metrics_summary['Model'].append('Voting Ensemble')\n",
    "metrics_summary['Val Accuracy'].append(accuracy_score(y_val, y_val_pred_vote))\n",
    "metrics_summary['Val Macro F1'].append(f1_score(y_val, y_val_pred_vote, average='macro'))\n",
    "metrics_summary['Test Accuracy'].append(accuracy_score(y_test, y_test_pred_vote))\n",
    "metrics_summary['Test Macro F1'].append(f1_score(y_test, y_test_pred_vote, average='macro'))\n",
    "\n",
    "summary_df = pd.DataFrame(metrics_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4351dd30-cd09-4a28-8acb-c973ea134202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Plot\n",
    "summary_df.set_index('Model')[['Val Accuracy', 'Val Macro F1']].plot(kind='bar', figsize=(8, 5), color=['steelblue', 'seagreen'])\n",
    "plt.title('Model Comparison: Accuracy and Macro F1')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0.75, 0.90)\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43a31eb-f054-41d0-9fdb-65bbb004db07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Plot\n",
    "summary_df.set_index('Model')[['Test Accuracy', 'Test Macro F1']].plot(kind='bar', figsize=(8, 5), color=['orange', 'tomato'])\n",
    "plt.title('Model Comparison: Test Accuracy and Macro F1')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0.75, 0.90)\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4c4f25-dc8a-45fb-8b3d-cc6d989e7480",
   "metadata": {},
   "source": [
    "### Final Evaluation Summary\n",
    "\n",
    "\n",
    "## Section C.2 - Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5924f7-56c9-40d4-99d0-a5154777f1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
